<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>我“毕业”了</title>
    <url>/undefined/undefined/undefined/undefined-world.md/</url>
    <content><![CDATA[<h2 id="“毕业”了"><a href="#“毕业”了" class="headerlink" title="“毕业”了"></a>“毕业”了</h2><h3 id="班长毕业了，我也大三了"><a href="#班长毕业了，我也大三了" class="headerlink" title="班长毕业了，我也大三了"></a>班长毕业了，我也大三了</h3><p>此刻的我非常激动，正好昨天才把这个博客“拯救”过来——之前一直因为想要优化一下这个主题，但是一直出问题，所以一直把博客搁置了，现在虽然也还没优化，但是还是可以简单写写文章的。</p>
<p>今天举行了班委换届，前几天准备了一个总结稿，站在台上的那一刻我是真没想到有点小紧张，差点开不了口。好在最后还是圆满结束了。</p>
<p>这一次应该是我最后一次以学生的身份站在讲台上发言。这次的发言是可以不需要的，只是单纯源于自己的“表达欲”，这也是我一年前的现在在台上竞选班长时说的话，我很想找个机会把内心最真诚的想法说给大家听。这也是我男生节的时候给班上每一位男生都认真写了一封信的原因。也是我报名蓝信封的原因。也是我创建这个博客的原因。更是我创建个人公众号发表“文字”的原因。</p>
<p>就在昨天我还在焦虑，反复问自己，好像自己一直以来都没有特别想干的事情，也没有一直干下去某一件事。写到这里，我发现，“文字”就是我的热爱。从初中大大小小记录“名言”的小本本，到高中三年的“吐槽”本，再到大学偶尔的记录。</p>
<p>文字的力量真的是纯粹的，我会反反复复阅读我灵感迸发后洋洋洒洒的几句话，也会在看到以前的字迹时回忆起当年的自己。</p>
<p>（或许以后找不到工作我会想去当语文老师吧，六年的语文课代表也是一件我值得骄傲的事情。）</p>
<p>而现在，“文字”在帮助我平复我激动的内心。</p>
<p>大二这一年，就好像我的高中，过的很快，但是一毕业就已经回想不起来了。我只记得很累，但是这种累应该不只是学生工作带来的，主要还是因为自己追星和实验室的缘故。大二这一年，我经历了极端的兴奋（线下演唱会）、极端的放弃（期末考的前一天晚上还在看综艺、六级差点就不去考了）、极端的纠结（实验室的任务）、极端的痛苦（暑假回不了家还要抉择接不接下任务）和极端的焦虑（该考研还是直接找工作，我到底有没有能力保研）。</p>
<p>回马灯已经不能完整的放出来了，直到现在我还在努力回想我的大二，但是仍然是一片空白。</p>
<p>就在我后悔没有把握好时间时，他们的回应让我的大二一年找回了存在的意义。</p>
<h5 id="“纯粹的热情”"><a href="#“纯粹的热情”" class="headerlink" title="“纯粹的热情”"></a>“纯粹的热情”</h5><p>她是这个班上最懂我的人，我们也是因为“文字”相熟。</p>
<p>还有其他一些对我给予肯定和赞扬的同学，不排除有客套的存在，但是能提供情绪价值的客套又有什么不好呢？</p>
<p>这一年，我确实学会了很多。刚当上班长的时候我性子很急，学校发个什么事我会很想又快又好的把它完成。这就不免会造成其他同事或同学的不满。而现在，我学会了冷静分析，慢慢来。班长期间还和学委发生过矛盾，但是我也学着有效解决。至于自己的焦虑，我虽然还是没有答案，不知道未来会怎样，但是三子说了</p>
<h5 id="“想，全是问题，做，全是答案”"><a href="#“想，全是问题，做，全是答案”" class="headerlink" title="“想，全是问题，做，全是答案”"></a>“想，全是问题，做，全是答案”</h5><p>感谢这一年的经历，好的坏的都是我自己。</p>
]]></content>
      <categories>
        <category>life</category>
        <category>school life</category>
      </categories>
  </entry>
  <entry>
    <title>Welcome</title>
    <url>/undefined/undefined/undefined/undefined-world.md/</url>
    <content><![CDATA[<p>欢迎来到皮皮休的博客，在这里，博主收集了大学生活中的各种学习资源，也有各种大学牲日常唠嗑、学习记录。作为一名大一新生，此博客将记录未来成长的点滴，寻找方向的路上任重而道远，不管外界如何，保持初心，一步一脚印……</p>
]]></content>
  </entry>
  <entry>
    <title>我好像一事无成</title>
    <url>/undefined/undefined/undefined/undefined-world.md/</url>
    <content><![CDATA[<p>大三了，我好像没有做成过一件什么事情。或许你会说“只要努力了就不会后悔”，考试我后悔，因为我不努力。</p>
<p>大一好像拼尽了全力，但是由于疫情，考试推迟到开学，所以我没有好好复习。虽然勉强进了前十，但是没有困难生，所以申请不了国家励志奖学金。</p>
<p>大二处于完全放弃的状态，所以即使我是困难生，我成绩掉到了17，连推免的资格都没有。更别提奖学金了。</p>
<p>现在说这些好像都是在后悔过去，我这辈子好像一直在后悔。后悔没进直升班，后悔没把物理考好，后悔选择了这个专业，后悔没有选择教授，也后悔大一大二的一切。</p>
<p>我好像把我的人生过得很糟，一切的轨迹都在向着反方向，我活成了最不想成为的人。</p>
<p>我怎么会没有理想呢。“人没有理想，那和咸鱼有什么分别”我也曾是个意气风发的少年。。。</p>
]]></content>
      <categories>
        <category>生活 -- 碎碎念</category>
      </categories>
  </entry>
  <entry>
    <title>论文精读1</title>
    <url>/undefined/undefined/undefined/undefined-world.md/</url>
    <content><![CDATA[<h1 id="Learning-Background-Prompts-to-Discover-Implicit-Knowledge-for-Open-Vocabulary-Object-Detection"><a href="#Learning-Background-Prompts-to-Discover-Implicit-Knowledge-for-Open-Vocabulary-Object-Detection" class="headerlink" title="Learning Background Prompts to Discover Implicit Knowledge for Open Vocabulary Object Detection"></a><center>Learning Background Prompts to Discover Implicit Knowledge for Open Vocabulary Object Detection</h1><h3 id="开放词汇目标检测任务中的学习背景提示来挖掘隐形背景知识"><a href="#开放词汇目标检测任务中的学习背景提示来挖掘隐形背景知识" class="headerlink" title="开放词汇目标检测任务中的学习背景提示来挖掘隐形背景知识"></a><center>开放词汇目标检测任务中的学习背景提示来挖掘隐形背景知识</h3><h4 id="3-2-1-Background-Category-specific-Prompt"><a href="#3-2-1-Background-Category-specific-Prompt" class="headerlink" title="3.2.1 Background Category-specific Prompt"></a>3.2.1 Background Category-specific Prompt</h4><p>在这个部分中，我们对开放词汇目标检测中背景候选框的底层类别进行建模，并且学习相应的特定类别的提示。然而，由于缺乏这些类别的先验知识，就需要对背景候选框的最优数目进行估计。</p>
<p>因此，我们首先使用一个与类无关的RPN模块在基类上训练，为每张图片得到背景候选框，采用的是VL-PLM中类似的技术。</p>
<h4 id="3-2-2-Background-Object-Discovery"><a href="#3-2-2-Background-Object-Discovery" class="headerlink" title="3.2.2 Background Object Discovery"></a>3.2.2 Background Object Discovery</h4><p>为了增强模型的训练，本文引入了一个在线的背景物体发现模块来有效地发现挖掘未知物体知识。这一模块旨在提取从与背景候选框中估计到的底层类别相关的隐性物体知识。为了简化，本文将Co划分成…</p>
<p>在训练的初始阶段，给定估计的背景类别数量n，在视觉嵌入集合上执行K值聚类（k设置为n），这个视觉嵌入集合是由CLIP的图像编码器为背景候选框而生成的。随后得到聚类中心的嵌入，记作w。这些聚类中心被看作是估计的背景类别的嵌入中心，允许在每一个训练批次中从背景候选框在线生成伪标签。受 VL-PLM启发，每一个训练批次的背景候选框会基于RPN分数进行过滤，阈值为θ，并增加一个步骤来过滤和真实边界框重叠的候选框。随后，CLIP用于生成伪标签，避免了检测器偏向估计的背景类别。</p>
<p>候选框x被分类为类别c的概率记作：</p>
<p>一旦这样的背景候选框具有对应于c中所有类别的概率分数，我们选择具有最高分数的预测类别标签作为其伪标签。</p>
<p>为了消除上述生成的置信度低的伪标签，我们将根据伪标签的概率分数使用阈值θ过滤候选框。参考VL-PLM，我们也对每一种类别应用非极大值抑制、使用感兴趣区域头部优化边界框预测，生成最终的伪标签。之后，使用最终的伪标签来为每一个训练批次的背景候选框分配类标签。设NBp表示Co中分配了类别标签的背景框集合，剩余的候选框被记作NBn。</p>
<p>λbg是一个用于背景候选框的小值损失权重，这个损失函数强调将背景候选框的视觉嵌入与从C估计出的背景类别相关的上下文嵌入对齐。这对于C中的大多数类别尤其关键，这些类别更容易出现知识丢失。此外，它还增强了BOD对背景候选框中隐含对象的洞察性知识的挖掘。</p>
<h4 id="3-2-3-Inference-Probability-Rectification"><a href="#3-2-3-Inference-Probability-Rectification" class="headerlink" title="3.2.3 Inference Probability Rectification"></a>3.2.3 Inference Probability Rectification</h4><p>前两个模块执行完之后，检测器识别未知类别的能力显著提升。然而推理中会出现新的挑战。训练时从背景候选框估计到的背景底层类别Co可能和推理时分类检测器的新类别Cu存在语义相似性。这样一来，</p>
<h3 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4.Experiments"></a>4.Experiments</h3><h4 id="4-1-Experiments-Setups"><a href="#4-1-Experiments-Setups" class="headerlink" title="4.1.Experiments Setups"></a>4.1.Experiments Setups</h4><p>数据集。为了评估提出的LBP框架在解决开放词汇目标检测问题上的有效性，文章在已提出的两个目标检测数据集上进行实验：MS-COCO和LVIS。这些实验是在传统的开放词汇设置中进行的，分别被称为OV-COCO和OV-LVIS。正如之前的工作所述，在OV-COCO任务中，我们将48个类别划分为基类，17个类别划分为新类。评估检测性能的指标主要是IoU下的平均精度（阈值为0.5）具体来说，</p>
]]></content>
      <categories>
        <category>papers</category>
        <category>Intensive Reading</category>
      </categories>
  </entry>
</search>
